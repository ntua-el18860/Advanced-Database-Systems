{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6242b564-729c-4432-b135-1a85a2d5104b",
   "metadata": {},
   "source": [
    "# Experimentation with BROADCAST, MERGE, SHUFFLE_HASH, SHUFFLE_REPLICATE_NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b105a204-ab23-4005-b345-facfe99b3b21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1863</td><td>application_1732639283265_1824</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_1824/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-174.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_1824_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load data\n",
    "from sedona.spark import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Join Strategies\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "# Read the file from s3\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = sedona.read.format(\"geojson\") \\\n",
    "            .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "            .selectExpr(\"explode(features) as features\") \\\n",
    "            .select(\"features.*\")\n",
    "# Formatting magic\n",
    "flattened_df = blocks_df.select( \\\n",
    "                [col(f\"properties.{col_name}\").alias(col_name) for col_name in \\\n",
    "                blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]) \\\n",
    "            .drop(\"properties\") \\\n",
    "            .drop(\"type\")\n",
    "#crime datas\n",
    "\n",
    "data_path = 's3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv'\n",
    "\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "data2_path = 's3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv'\n",
    "df2 = spark.read.csv(data2_path,header = True, inferSchema = True)\n",
    "\n",
    "df_combined = df.union(df2)\n",
    "\n",
    "#load data from LA income\n",
    "data3_path = 's3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv'\n",
    "df3 = spark.read.csv(data3_path,header = True, inferSchema = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ee1eda-07f7-4b6e-a131-121ee01e4316",
   "metadata": {},
   "source": [
    "## Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f2f5bc-fba4-45a6-a9f3-6c66b76aff9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_1\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "|Community       |Total Population|Total Households|Estimated Median Income per Household|Income per Individual|\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "|Culver City     |77766           |34982           |$75,913.50                           |$34,148.68           |\n",
      "|Pico Rivera     |62942           |17109           |$55,758.00                           |$15,156.23           |\n",
      "|Malibu          |12645           |6864            |$123,681.00                          |$67,136.92           |\n",
      "|Hacienda Heights|53594           |16524           |$78,000.00                           |$24,048.81           |\n",
      "|Montebello      |62500           |19768           |$45,898.00                           |$14,516.99           |\n",
      "|Hawaiian Gardens|14254           |3703            |$37,543.00                           |$9,753.17            |\n",
      "|Westlake Village|16540           |6768            |$104,382.50                          |$42,712.26           |\n",
      "|Carson          |183428          |52452           |$74,351.50                           |$21,261.12           |\n",
      "|Glendale        |1150314         |457614          |$66,520.33                           |$26,462.89           |\n",
      "|Signal Hill     |11016           |4389            |$65,935.00                           |$26,269.85           |\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time taken: 14.76 seconds"
     ]
    }
   ],
   "source": [
    "print(\"Task_1\")\n",
    "start_time = time.time()\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Join με την βάση df3\n",
    "joined_df = flattened_df.hint(\"broadcast\").join(df3, flattened_df[\"COMM\"] == df3[\"Community\"], \"inner\")\n",
    "\n",
    "# Καθαρισμός της στήλης \"Estimated Median Income\"\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"Cleaned Estimated Median Income\",\n",
    "    F.regexp_replace(F.col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(\"double\")\n",
    ")\n",
    "joined_df.select(\"Community\",\"Cleaned Estimated Median Income\",\"POP_2010\",\"HOUSING10\")\n",
    "# Ομαδοποίηση κατά την περιοχή \"Community\" και υπολογισμός των απαιτούμενων τιμών\n",
    "grouped_df = joined_df.groupBy(\"Community\").agg(\n",
    "    F.sum(\"POP_2010\").alias(\"Total Population\"),\n",
    "    F.sum(\"HOUSING10\").alias(\"Total Households\"),\n",
    "    F.avg(\"Cleaned Estimated Median Income\").alias(\"Avg Estimated Median Income\")\n",
    ")\n",
    "\n",
    "# Υπολογισμός της στήλης \"Income per Individual\"\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Income per Individual\",\n",
    "    (F.col(\"Total Households\") * F.col(\"Avg Estimated Median Income\")) / F.col(\"Total Population\")\n",
    ")\n",
    "\n",
    "# Δημιουργία της στήλης με το δολάριο για τα αποτελέσματα\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Estimated Median Income per Household\",\n",
    "    F.concat(F.lit(\"$\"), F.format_number(F.col(\"Avg Estimated Median Income\"), 2))\n",
    ")\n",
    "\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Income per Individual\",\n",
    "    F.concat(F.lit(\"$\"), F.format_number(F.col(\"Income per Individual\"), 2))\n",
    ")\n",
    "\n",
    "# Επιλογή των στηλών για εμφάνιση\n",
    "result_df = grouped_df.select(\n",
    "    \"Community\", \n",
    "    \"Total Population\", \n",
    "    \"Total Households\", \n",
    "    \"Estimated Median Income per Household\",\n",
    "    \"Income per Individual\"\n",
    ")\n",
    "\n",
    "# Εμφάνιση του αποτελέσματος\n",
    "result_df.show(truncate=False,n=10)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d36c09-116f-4134-85c9-7802e25e2dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_2\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "|Community       |Total Population|Sum_of_Crimes|Ratio_of_Crimes_Per_Person|\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "|Culver City     |77766           |2780         |0.03574827045238279       |\n",
      "|Pico Rivera     |62942           |2            |3.177528518318452E-5      |\n",
      "|Malibu          |12645           |1            |7.908264136022143E-5      |\n",
      "|Hacienda Heights|53594           |NULL         |NULL                      |\n",
      "|Montebello      |62500           |6            |9.6E-5                    |\n",
      "|Hawaiian Gardens|14254           |NULL         |NULL                      |\n",
      "|Westlake Village|16540           |2            |1.2091898428053205E-4     |\n",
      "|Carson          |183428          |862          |0.004699391586889679      |\n",
      "|Glendale        |1150314         |816          |7.093715281218867E-4      |\n",
      "|Signal Hill     |11016           |2            |1.8155410312273057E-4     |\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time taken: 88.68 seconds"
     ]
    }
   ],
   "source": [
    "print(\"Task_2\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Βήμα 1: Προσθήκη στήλης για γεωμετρικά σημεία στα δεδομένα εγκλημάτων\n",
    "df_combined = df_combined.withColumn(\"geom\", ST_Point(\"LON\", \"LAT\"))\n",
    "\n",
    "# Βήμα 2: Εντοπισμός αν τα σημεία ανήκουν σε κάποιο πολύγωνο\n",
    "df_joined = flattened_df.join(\n",
    "    df_combined,\n",
    "    ST_Contains(flattened_df[\"geometry\"], df_combined[\"geom\"]),\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_zip = df_joined.join(df3, df_joined[\"COMM\"] == df3[\"Community\"], \"inner\")\n",
    "\n",
    "df_zip.select(\"Community\",\"geometry\")\n",
    "# Βήμα 3: Προσθήκη στήλης \"Sum of Crimes\"\n",
    "df_aggregated = df_zip.groupBy(\"Community\").agg(\n",
    "    _sum(col(\"geometry\").isNotNull().cast(\"int\")).alias(\"Sum_of_Crimes\")\n",
    ")\n",
    "\n",
    "df_final=result_df.join(df_aggregated, result_df['Community'] == df_aggregated['Community'], \"left\")\n",
    "\n",
    "# Βήμα 4: Υπολογισμός της στήλης \"Ratio_of_Crimes_Per_Person\"\n",
    "df_final = df_final.withColumn(\n",
    "    \"Ratio_of_Crimes_Per_Person\", \n",
    "    col(\"Sum_of_Crimes\") / col(\"Total Population\")\n",
    ")\n",
    "\n",
    "# Βήμα 5: Εμφάνιση των αποτελεσμάτων\n",
    "df_final = df_final.select(result_df['Community'],\"Total Population\",\"Sum_of_Crimes\",\"Ratio_of_Crimes_Per_Person\")\n",
    "\n",
    "# Προβολή των αποτελεσμάτων\n",
    "df_final.show(truncate=False,n=10)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0fe1f98-152f-43a2-802f-08d0943e4894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (15)\n",
      "+- Project (14)\n",
      "   +- HashAggregate (13)\n",
      "      +- Exchange (12)\n",
      "         +- HashAggregate (11)\n",
      "            +- Project (10)\n",
      "               +- BroadcastHashJoin Inner BuildLeft (9)\n",
      "                  :- BroadcastExchange (6)\n",
      "                  :  +- Project (5)\n",
      "                  :     +- Filter (4)\n",
      "                  :        +- Generate (3)\n",
      "                  :           +- Filter (2)\n",
      "                  :              +- Scan geojson  (1)\n",
      "                  +- Filter (8)\n",
      "                     +- Scan csv  (7)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#25]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#25]\n",
      "Condition : ((size(features#25, true) > 0) AND isnotnull(features#25))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#25]\n",
      "Arguments: explode(features#25), false, [features#33]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : isnotnull(features#33.properties.COMM)\n",
      "\n",
      "(5) Project\n",
      "Output [3]: [features#33.properties.COMM AS COMM#49, features#33.properties.HOUSING10 AS HOUSING10#55L, features#33.properties.POP_2010 AS POP_2010#58L]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(6) BroadcastExchange\n",
      "Input [3]: [COMM#49, HOUSING10#55L, POP_2010#58L]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=1090]\n",
      "\n",
      "(7) Scan csv \n",
      "Output [2]: [Community#365, Estimated Median Income#366]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string,Estimated Median Income:string>\n",
      "\n",
      "(8) Filter\n",
      "Input [2]: [Community#365, Estimated Median Income#366]\n",
      "Condition : isnotnull(Community#365)\n",
      "\n",
      "(9) BroadcastHashJoin\n",
      "Left keys [1]: [COMM#49]\n",
      "Right keys [1]: [Community#365]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(10) Project\n",
      "Output [4]: [HOUSING10#55L, POP_2010#58L, Community#365, cast(regexp_replace(Estimated Median Income#366, [$,], , 1) as double) AS Cleaned Estimated Median Income#429]\n",
      "Input [5]: [COMM#49, HOUSING10#55L, POP_2010#58L, Community#365, Estimated Median Income#366]\n",
      "\n",
      "(11) HashAggregate\n",
      "Input [4]: [HOUSING10#55L, POP_2010#58L, Community#365, Cleaned Estimated Median Income#429]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [3]: [partial_sum(POP_2010#58L), partial_sum(HOUSING10#55L), partial_avg(Cleaned Estimated Median Income#429)]\n",
      "Aggregate Attributes [4]: [sum#545L, sum#547L, sum#549, count#550L]\n",
      "Results [5]: [Community#365, sum#546L, sum#548L, sum#551, count#552L]\n",
      "\n",
      "(12) Exchange\n",
      "Input [5]: [Community#365, sum#546L, sum#548L, sum#551, count#552L]\n",
      "Arguments: hashpartitioning(Community#365, 1000), ENSURE_REQUIREMENTS, [plan_id=1095]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [5]: [Community#365, sum#546L, sum#548L, sum#551, count#552L]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [3]: [sum(POP_2010#58L), sum(HOUSING10#55L), avg(Cleaned Estimated Median Income#429)]\n",
      "Aggregate Attributes [3]: [sum(POP_2010#58L)#494L, sum(HOUSING10#55L)#496L, avg(Cleaned Estimated Median Income#429)#498]\n",
      "Results [4]: [Community#365, sum(POP_2010#58L)#494L AS Total Population#495L, sum(HOUSING10#55L)#496L AS Total Households#497L, avg(Cleaned Estimated Median Income#429)#498 AS Avg Estimated Median Income#499]\n",
      "\n",
      "(14) Project\n",
      "Output [5]: [Community#365, Total Population#495L, Total Households#497L, concat($, format_number(Avg Estimated Median Income#499, 2)) AS Estimated Median Income per Household#510, concat($, format_number(((cast(Total Households#497L as double) * Avg Estimated Median Income#499) / cast(Total Population#495L as double)), 2)) AS Income per Individual#517]\n",
      "Input [4]: [Community#365, Total Population#495L, Total Households#497L, Avg Estimated Median Income#499]\n",
      "\n",
      "(15) AdaptiveSparkPlan\n",
      "Output [5]: [Community#365, Total Population#495L, Total Households#497L, Estimated Median Income per Household#510, Income per Individual#517]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (40)\n",
      "+- Project (39)\n",
      "   +- SortMergeJoin LeftOuter (38)\n",
      "      :- Sort (14)\n",
      "      :  +- HashAggregate (13)\n",
      "      :     +- Exchange (12)\n",
      "      :        +- HashAggregate (11)\n",
      "      :           +- Project (10)\n",
      "      :              +- BroadcastHashJoin Inner BuildLeft (9)\n",
      "      :                 :- BroadcastExchange (6)\n",
      "      :                 :  +- Project (5)\n",
      "      :                 :     +- Filter (4)\n",
      "      :                 :        +- Generate (3)\n",
      "      :                 :           +- Filter (2)\n",
      "      :                 :              +- Scan geojson  (1)\n",
      "      :                 +- Filter (8)\n",
      "      :                    +- Scan csv  (7)\n",
      "      +- Sort (37)\n",
      "         +- HashAggregate (36)\n",
      "            +- Exchange (35)\n",
      "               +- HashAggregate (34)\n",
      "                  +- Project (33)\n",
      "                     +- BroadcastHashJoin Inner BuildRight (32)\n",
      "                        :- Project (28)\n",
      "                        :  +- RangeJoin (27)\n",
      "                        :     :- Project (19)\n",
      "                        :     :  +- Filter (18)\n",
      "                        :     :     +- Generate (17)\n",
      "                        :     :        +- Filter (16)\n",
      "                        :     :           +- Scan geojson  (15)\n",
      "                        :     +- Union (26)\n",
      "                        :        :- Project (22)\n",
      "                        :        :  +- Filter (21)\n",
      "                        :        :     +- Scan csv  (20)\n",
      "                        :        +- Project (25)\n",
      "                        :           +- Filter (24)\n",
      "                        :              +- Scan csv  (23)\n",
      "                        +- BroadcastExchange (31)\n",
      "                           +- Filter (30)\n",
      "                              +- Scan csv  (29)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#25]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#25]\n",
      "Condition : ((size(features#25, true) > 0) AND isnotnull(features#25))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#25]\n",
      "Arguments: explode(features#25), false, [features#33]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : isnotnull(features#33.properties.COMM)\n",
      "\n",
      "(5) Project\n",
      "Output [2]: [features#33.properties.COMM AS COMM#49, features#33.properties.POP_2010 AS POP_2010#58L]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(6) BroadcastExchange\n",
      "Input [2]: [COMM#49, POP_2010#58L]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=1293]\n",
      "\n",
      "(7) Scan csv \n",
      "Output [1]: [Community#365]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string>\n",
      "\n",
      "(8) Filter\n",
      "Input [1]: [Community#365]\n",
      "Condition : isnotnull(Community#365)\n",
      "\n",
      "(9) BroadcastHashJoin\n",
      "Left keys [1]: [COMM#49]\n",
      "Right keys [1]: [Community#365]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(10) Project\n",
      "Output [2]: [POP_2010#58L, Community#365]\n",
      "Input [3]: [COMM#49, POP_2010#58L, Community#365]\n",
      "\n",
      "(11) HashAggregate\n",
      "Input [2]: [POP_2010#58L, Community#365]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [1]: [partial_sum(POP_2010#58L)]\n",
      "Aggregate Attributes [1]: [sum#545L]\n",
      "Results [2]: [Community#365, sum#546L]\n",
      "\n",
      "(12) Exchange\n",
      "Input [2]: [Community#365, sum#546L]\n",
      "Arguments: hashpartitioning(Community#365, 1000), ENSURE_REQUIREMENTS, [plan_id=1298]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [2]: [Community#365, sum#546L]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [1]: [sum(POP_2010#58L)]\n",
      "Aggregate Attributes [1]: [sum(POP_2010#58L)#494L]\n",
      "Results [2]: [Community#365, sum(POP_2010#58L)#494L AS Total Population#495L]\n",
      "\n",
      "(14) Sort\n",
      "Input [2]: [Community#365, Total Population#495L]\n",
      "Arguments: [Community#365 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(15) Scan geojson \n",
      "Output [1]: [features#910]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(16) Filter\n",
      "Input [1]: [features#910]\n",
      "Condition : ((size(features#910, true) > 0) AND isnotnull(features#910))\n",
      "\n",
      "(17) Generate\n",
      "Input [1]: [features#910]\n",
      "Arguments: explode(features#910), false, [features#33]\n",
      "\n",
      "(18) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : (isnotnull(features#33.geometry) AND isnotnull(features#33.properties.COMM))\n",
      "\n",
      "(19) Project\n",
      "Output [2]: [features#33.properties.COMM AS COMM#49, features#33.geometry AS geometry#36]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(20) Scan csv \n",
      "Output [2]: [LAT#214, LON#215]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(21) Filter\n",
      "Input [2]: [LAT#214, LON#215]\n",
      "Condition : isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )\n",
      "\n",
      "(22) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#589]\n",
      "Input [2]: [LAT#214, LON#215]\n",
      "\n",
      "(23) Scan csv \n",
      "Output [2]: [LAT#288, LON#289]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(24) Filter\n",
      "Input [2]: [LAT#288, LON#289]\n",
      "Condition : isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )\n",
      "\n",
      "(25) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#1013]\n",
      "Input [2]: [LAT#288, LON#289]\n",
      "\n",
      "(26) Union\n",
      "\n",
      "(27) RangeJoin\n",
      "Arguments: geometry#36: geometry, geom#589: geometry, CONTAINS\n",
      "\n",
      "(28) Project\n",
      "Output [2]: [COMM#49, geometry#36]\n",
      "Input [3]: [COMM#49, geometry#36, geom#589]\n",
      "\n",
      "(29) Scan csv \n",
      "Output [1]: [Community#914]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string>\n",
      "\n",
      "(30) Filter\n",
      "Input [1]: [Community#914]\n",
      "Condition : isnotnull(Community#914)\n",
      "\n",
      "(31) BroadcastExchange\n",
      "Input [1]: [Community#914]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=1300]\n",
      "\n",
      "(32) BroadcastHashJoin\n",
      "Left keys [1]: [COMM#49]\n",
      "Right keys [1]: [Community#914]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(33) Project\n",
      "Output [2]: [geometry#36, Community#914]\n",
      "Input [3]: [COMM#49, geometry#36, Community#914]\n",
      "\n",
      "(34) HashAggregate\n",
      "Input [2]: [geometry#36, Community#914]\n",
      "Keys [1]: [Community#914]\n",
      "Functions [1]: [partial_sum(cast(isnotnull(geometry#36) as int))]\n",
      "Aggregate Attributes [1]: [sum#959L]\n",
      "Results [2]: [Community#914, sum#960L]\n",
      "\n",
      "(35) Exchange\n",
      "Input [2]: [Community#914, sum#960L]\n",
      "Arguments: hashpartitioning(Community#914, 1000), ENSURE_REQUIREMENTS, [plan_id=1305]\n",
      "\n",
      "(36) HashAggregate\n",
      "Input [2]: [Community#914, sum#960L]\n",
      "Keys [1]: [Community#914]\n",
      "Functions [1]: [sum(cast(isnotnull(geometry#36) as int))]\n",
      "Aggregate Attributes [1]: [sum(cast(isnotnull(geometry#36) as int))#905L]\n",
      "Results [2]: [Community#914, sum(cast(isnotnull(geometry#36) as int))#905L AS Sum_of_Crimes#906L]\n",
      "\n",
      "(37) Sort\n",
      "Input [2]: [Community#914, Sum_of_Crimes#906L]\n",
      "Arguments: [Community#914 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(38) SortMergeJoin\n",
      "Left keys [1]: [Community#365]\n",
      "Right keys [1]: [Community#914]\n",
      "Join type: LeftOuter\n",
      "Join condition: None\n",
      "\n",
      "(39) Project\n",
      "Output [4]: [Community#365, Total Population#495L, Sum_of_Crimes#906L, (cast(Sum_of_Crimes#906L as double) / cast(Total Population#495L as double)) AS Ratio_of_Crimes_Per_Person#932]\n",
      "Input [4]: [Community#365, Total Population#495L, Community#914, Sum_of_Crimes#906L]\n",
      "\n",
      "(40) AdaptiveSparkPlan\n",
      "Output [4]: [Community#365, Total Population#495L, Sum_of_Crimes#906L, Ratio_of_Crimes_Per_Person#932]\n",
      "Arguments: isFinalPlan=false"
     ]
    }
   ],
   "source": [
    "result_df.explain(mode=\"formatted\")\n",
    "df_final.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a40adf9-8dc6-4e29-b851-47297ea13d6e",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4397a3-f4a6-48a3-8075-ed22a727454f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_1\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "|Community       |Total Population|Total Households|Estimated Median Income per Household|Income per Individual|\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "|Carson          |183428          |52452           |$74,351.50                           |$21,261.12           |\n",
      "|Claremont       |35348           |12306           |$89,161.00                           |$31,040.38           |\n",
      "|Culver City     |77766           |34982           |$75,913.50                           |$34,148.68           |\n",
      "|Gardena         |176487          |64416           |$49,137.67                           |$17,934.76           |\n",
      "|Glendale        |1150314         |457614          |$66,520.33                           |$26,462.89           |\n",
      "|Glendora        |101388          |35964           |$76,010.00                           |$26,962.00           |\n",
      "|Hacienda Heights|53594           |16524           |$78,000.00                           |$24,048.81           |\n",
      "|Hawaiian Gardens|14254           |3703            |$37,543.00                           |$9,753.17            |\n",
      "|Malibu          |12645           |6864            |$123,681.00                          |$67,136.92           |\n",
      "|Montebello      |62500           |19768           |$45,898.00                           |$14,516.99           |\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time taken: 11.43 seconds"
     ]
    }
   ],
   "source": [
    "print(\"Task_1\")\n",
    "start_time = time.time()\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Join με την βάση df3\n",
    "joined_df = flattened_df.hint(\"merge\").join(df3, flattened_df[\"COMM\"] == df3[\"Community\"], \"inner\")\n",
    "\n",
    "# Καθαρισμός της στήλης \"Estimated Median Income\"\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"Cleaned Estimated Median Income\",\n",
    "    F.regexp_replace(F.col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(\"double\")\n",
    ")\n",
    "joined_df.select(\"Community\",\"Cleaned Estimated Median Income\",\"POP_2010\",\"HOUSING10\")\n",
    "# Ομαδοποίηση κατά την περιοχή \"Community\" και υπολογισμός των απαιτούμενων τιμών\n",
    "grouped_df = joined_df.groupBy(\"Community\").agg(\n",
    "    F.sum(\"POP_2010\").alias(\"Total Population\"),\n",
    "    F.sum(\"HOUSING10\").alias(\"Total Households\"),\n",
    "    F.avg(\"Cleaned Estimated Median Income\").alias(\"Avg Estimated Median Income\")\n",
    ")\n",
    "\n",
    "# Υπολογισμός της στήλης \"Income per Individual\"\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Income per Individual\",\n",
    "    (F.col(\"Total Households\") * F.col(\"Avg Estimated Median Income\")) / F.col(\"Total Population\")\n",
    ")\n",
    "\n",
    "# Δημιουργία της στήλης με το δολάριο για τα αποτελέσματα\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Estimated Median Income per Household\",\n",
    "    F.concat(F.lit(\"$\"), F.format_number(F.col(\"Avg Estimated Median Income\"), 2))\n",
    ")\n",
    "\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Income per Individual\",\n",
    "    F.concat(F.lit(\"$\"), F.format_number(F.col(\"Income per Individual\"), 2))\n",
    ")\n",
    "\n",
    "# Επιλογή των στηλών για εμφάνιση\n",
    "result_df = grouped_df.select(\n",
    "    \"Community\", \n",
    "    \"Total Population\", \n",
    "    \"Total Households\", \n",
    "    \"Estimated Median Income per Household\",\n",
    "    \"Income per Individual\"\n",
    ")\n",
    "\n",
    "# Εμφάνιση του αποτελέσματος\n",
    "result_df.show(truncate=False,n=10)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1259e24b-a1f5-482c-96f6-17ef78964bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_2\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "|Community       |Total Population|Sum_of_Crimes|Ratio_of_Crimes_Per_Person|\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "|Culver City     |77766           |2780         |0.03574827045238279       |\n",
      "|Hacienda Heights|53594           |NULL         |NULL                      |\n",
      "|Hawaiian Gardens|14254           |NULL         |NULL                      |\n",
      "|Malibu          |12645           |1            |7.908264136022143E-5      |\n",
      "|Montebello      |62500           |6            |9.6E-5                    |\n",
      "|Pico Rivera     |62942           |2            |3.177528518318452E-5      |\n",
      "|Westlake Village|16540           |2            |1.2091898428053205E-4     |\n",
      "|Carson          |183428          |862          |0.004699391586889679      |\n",
      "|Glendale        |1150314         |816          |7.093715281218867E-4      |\n",
      "|Claremont       |35348           |6            |1.697408622835804E-4      |\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time taken: 91.60 seconds"
     ]
    }
   ],
   "source": [
    "print(\"Task_2\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Βήμα 1: Προσθήκη στήλης για γεωμετρικά σημεία στα δεδομένα εγκλημάτων\n",
    "df_combined = df_combined.withColumn(\"geom\", ST_Point(\"LON\", \"LAT\"))\n",
    "\n",
    "# Βήμα 2: Εντοπισμός αν τα σημεία ανήκουν σε κάποιο πολύγωνο\n",
    "df_joined = flattened_df.hint(\"merge\").join(\n",
    "    df_combined,\n",
    "    ST_Contains(flattened_df[\"geometry\"], df_combined[\"geom\"]),\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_zip = df_joined.hint(\"merge\").join(df3, df_joined[\"COMM\"] == df3[\"Community\"], \"inner\")\n",
    "\n",
    "df_zip.select(\"Community\",\"geometry\")\n",
    "# Βήμα 3: Προσθήκη στήλης \"Sum of Crimes\"\n",
    "df_aggregated = df_zip.groupBy(\"Community\").agg(\n",
    "    _sum(col(\"geometry\").isNotNull().cast(\"int\")).alias(\"Sum_of_Crimes\")\n",
    ")\n",
    "\n",
    "df_final=result_df.hint(\"merge\").join(df_aggregated, result_df['Community'] == df_aggregated['Community'], \"left\")\n",
    "\n",
    "# Βήμα 4: Υπολογισμός της στήλης \"Ratio_of_Crimes_Per_Person\"\n",
    "df_final = df_final.withColumn(\n",
    "    \"Ratio_of_Crimes_Per_Person\", \n",
    "    col(\"Sum_of_Crimes\") / col(\"Total Population\")\n",
    ")\n",
    "\n",
    "# Βήμα 5: Εμφάνιση των αποτελεσμάτων\n",
    "df_final = df_final.select(result_df['Community'],\"Total Population\",\"Sum_of_Crimes\",\"Ratio_of_Crimes_Per_Person\")\n",
    "\n",
    "# Προβολή των αποτελεσμάτων\n",
    "df_final.show(truncate=False,n=10)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a255eae4-77be-45a5-bd1e-f3fe3705dc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (17)\n",
      "+- Project (16)\n",
      "   +- HashAggregate (15)\n",
      "      +- HashAggregate (14)\n",
      "         +- Project (13)\n",
      "            +- SortMergeJoin Inner (12)\n",
      "               :- Sort (7)\n",
      "               :  +- Exchange (6)\n",
      "               :     +- Project (5)\n",
      "               :        +- Filter (4)\n",
      "               :           +- Generate (3)\n",
      "               :              +- Filter (2)\n",
      "               :                 +- Scan geojson  (1)\n",
      "               +- Sort (11)\n",
      "                  +- Exchange (10)\n",
      "                     +- Filter (9)\n",
      "                        +- Scan csv  (8)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#25]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#25]\n",
      "Condition : ((size(features#25, true) > 0) AND isnotnull(features#25))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#25]\n",
      "Arguments: explode(features#25), false, [features#33]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : isnotnull(features#33.properties.COMM)\n",
      "\n",
      "(5) Project\n",
      "Output [3]: [features#33.properties.COMM AS COMM#49, features#33.properties.HOUSING10 AS HOUSING10#55L, features#33.properties.POP_2010 AS POP_2010#58L]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(6) Exchange\n",
      "Input [3]: [COMM#49, HOUSING10#55L, POP_2010#58L]\n",
      "Arguments: hashpartitioning(COMM#49, 1000), ENSURE_REQUIREMENTS, [plan_id=2509]\n",
      "\n",
      "(7) Sort\n",
      "Input [3]: [COMM#49, HOUSING10#55L, POP_2010#58L]\n",
      "Arguments: [COMM#49 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(8) Scan csv \n",
      "Output [2]: [Community#365, Estimated Median Income#366]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string,Estimated Median Income:string>\n",
      "\n",
      "(9) Filter\n",
      "Input [2]: [Community#365, Estimated Median Income#366]\n",
      "Condition : isnotnull(Community#365)\n",
      "\n",
      "(10) Exchange\n",
      "Input [2]: [Community#365, Estimated Median Income#366]\n",
      "Arguments: hashpartitioning(Community#365, 1000), ENSURE_REQUIREMENTS, [plan_id=2510]\n",
      "\n",
      "(11) Sort\n",
      "Input [2]: [Community#365, Estimated Median Income#366]\n",
      "Arguments: [Community#365 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(12) SortMergeJoin\n",
      "Left keys [1]: [COMM#49]\n",
      "Right keys [1]: [Community#365]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(13) Project\n",
      "Output [4]: [HOUSING10#55L, POP_2010#58L, Community#365, cast(regexp_replace(Estimated Median Income#366, [$,], , 1) as double) AS Cleaned Estimated Median Income#1082]\n",
      "Input [5]: [COMM#49, HOUSING10#55L, POP_2010#58L, Community#365, Estimated Median Income#366]\n",
      "\n",
      "(14) HashAggregate\n",
      "Input [4]: [HOUSING10#55L, POP_2010#58L, Community#365, Cleaned Estimated Median Income#1082]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [3]: [partial_sum(POP_2010#58L), partial_sum(HOUSING10#55L), partial_avg(Cleaned Estimated Median Income#1082)]\n",
      "Aggregate Attributes [4]: [sum#1197L, sum#1199L, sum#1201, count#1202L]\n",
      "Results [5]: [Community#365, sum#1198L, sum#1200L, sum#1203, count#1204L]\n",
      "\n",
      "(15) HashAggregate\n",
      "Input [5]: [Community#365, sum#1198L, sum#1200L, sum#1203, count#1204L]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [3]: [sum(POP_2010#58L), sum(HOUSING10#55L), avg(Cleaned Estimated Median Income#1082)]\n",
      "Aggregate Attributes [3]: [sum(POP_2010#58L)#1147L, sum(HOUSING10#55L)#1149L, avg(Cleaned Estimated Median Income#1082)#1151]\n",
      "Results [4]: [Community#365, sum(POP_2010#58L)#1147L AS Total Population#1148L, sum(HOUSING10#55L)#1149L AS Total Households#1150L, avg(Cleaned Estimated Median Income#1082)#1151 AS Avg Estimated Median Income#1152]\n",
      "\n",
      "(16) Project\n",
      "Output [5]: [Community#365, Total Population#1148L, Total Households#1150L, concat($, format_number(Avg Estimated Median Income#1152, 2)) AS Estimated Median Income per Household#1163, concat($, format_number(((cast(Total Households#1150L as double) * Avg Estimated Median Income#1152) / cast(Total Population#1148L as double)), 2)) AS Income per Individual#1170]\n",
      "Input [4]: [Community#365, Total Population#1148L, Total Households#1150L, Avg Estimated Median Income#1152]\n",
      "\n",
      "(17) AdaptiveSparkPlan\n",
      "Output [5]: [Community#365, Total Population#1148L, Total Households#1150L, Estimated Median Income per Household#1163, Income per Individual#1170]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (44)\n",
      "+- Project (43)\n",
      "   +- SortMergeJoin LeftOuter (42)\n",
      "      :- Sort (16)\n",
      "      :  +- HashAggregate (15)\n",
      "      :     +- HashAggregate (14)\n",
      "      :        +- Project (13)\n",
      "      :           +- SortMergeJoin Inner (12)\n",
      "      :              :- Sort (7)\n",
      "      :              :  +- Exchange (6)\n",
      "      :              :     +- Project (5)\n",
      "      :              :        +- Filter (4)\n",
      "      :              :           +- Generate (3)\n",
      "      :              :              +- Filter (2)\n",
      "      :              :                 +- Scan geojson  (1)\n",
      "      :              +- Sort (11)\n",
      "      :                 +- Exchange (10)\n",
      "      :                    +- Filter (9)\n",
      "      :                       +- Scan csv  (8)\n",
      "      +- Sort (41)\n",
      "         +- HashAggregate (40)\n",
      "            +- HashAggregate (39)\n",
      "               +- Project (38)\n",
      "                  +- SortMergeJoin Inner (37)\n",
      "                     :- Sort (32)\n",
      "                     :  +- Exchange (31)\n",
      "                     :     +- Project (30)\n",
      "                     :        +- RangeJoin (29)\n",
      "                     :           :- Project (21)\n",
      "                     :           :  +- Filter (20)\n",
      "                     :           :     +- Generate (19)\n",
      "                     :           :        +- Filter (18)\n",
      "                     :           :           +- Scan geojson  (17)\n",
      "                     :           +- Union (28)\n",
      "                     :              :- Project (24)\n",
      "                     :              :  +- Filter (23)\n",
      "                     :              :     +- Scan csv  (22)\n",
      "                     :              +- Project (27)\n",
      "                     :                 +- Filter (26)\n",
      "                     :                    +- Scan csv  (25)\n",
      "                     +- Sort (36)\n",
      "                        +- Exchange (35)\n",
      "                           +- Filter (34)\n",
      "                              +- Scan csv  (33)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#25]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#25]\n",
      "Condition : ((size(features#25, true) > 0) AND isnotnull(features#25))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#25]\n",
      "Arguments: explode(features#25), false, [features#33]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : isnotnull(features#33.properties.COMM)\n",
      "\n",
      "(5) Project\n",
      "Output [2]: [features#33.properties.COMM AS COMM#49, features#33.properties.POP_2010 AS POP_2010#58L]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(6) Exchange\n",
      "Input [2]: [COMM#49, POP_2010#58L]\n",
      "Arguments: hashpartitioning(COMM#49, 1000), ENSURE_REQUIREMENTS, [plan_id=2719]\n",
      "\n",
      "(7) Sort\n",
      "Input [2]: [COMM#49, POP_2010#58L]\n",
      "Arguments: [COMM#49 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(8) Scan csv \n",
      "Output [1]: [Community#365]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string>\n",
      "\n",
      "(9) Filter\n",
      "Input [1]: [Community#365]\n",
      "Condition : isnotnull(Community#365)\n",
      "\n",
      "(10) Exchange\n",
      "Input [1]: [Community#365]\n",
      "Arguments: hashpartitioning(Community#365, 1000), ENSURE_REQUIREMENTS, [plan_id=2720]\n",
      "\n",
      "(11) Sort\n",
      "Input [1]: [Community#365]\n",
      "Arguments: [Community#365 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(12) SortMergeJoin\n",
      "Left keys [1]: [COMM#49]\n",
      "Right keys [1]: [Community#365]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(13) Project\n",
      "Output [2]: [POP_2010#58L, Community#365]\n",
      "Input [3]: [COMM#49, POP_2010#58L, Community#365]\n",
      "\n",
      "(14) HashAggregate\n",
      "Input [2]: [POP_2010#58L, Community#365]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [1]: [partial_sum(POP_2010#58L)]\n",
      "Aggregate Attributes [1]: [sum#1197L]\n",
      "Results [2]: [Community#365, sum#1198L]\n",
      "\n",
      "(15) HashAggregate\n",
      "Input [2]: [Community#365, sum#1198L]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [1]: [sum(POP_2010#58L)]\n",
      "Aggregate Attributes [1]: [sum(POP_2010#58L)#1147L]\n",
      "Results [2]: [Community#365, sum(POP_2010#58L)#1147L AS Total Population#1148L]\n",
      "\n",
      "(16) Sort\n",
      "Input [2]: [Community#365, Total Population#1148L]\n",
      "Arguments: [Community#365 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(17) Scan geojson \n",
      "Output [1]: [features#1554]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(18) Filter\n",
      "Input [1]: [features#1554]\n",
      "Condition : ((size(features#1554, true) > 0) AND isnotnull(features#1554))\n",
      "\n",
      "(19) Generate\n",
      "Input [1]: [features#1554]\n",
      "Arguments: explode(features#1554), false, [features#33]\n",
      "\n",
      "(20) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : (isnotnull(features#33.geometry) AND isnotnull(features#33.properties.COMM))\n",
      "\n",
      "(21) Project\n",
      "Output [2]: [features#33.properties.COMM AS COMM#49, features#33.geometry AS geometry#36]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(22) Scan csv \n",
      "Output [2]: [LAT#214, LON#215]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(23) Filter\n",
      "Input [2]: [LAT#214, LON#215]\n",
      "Condition : isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )\n",
      "\n",
      "(24) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#1233]\n",
      "Input [2]: [LAT#214, LON#215]\n",
      "\n",
      "(25) Scan csv \n",
      "Output [2]: [LAT#288, LON#289]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(26) Filter\n",
      "Input [2]: [LAT#288, LON#289]\n",
      "Condition : isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )\n",
      "\n",
      "(27) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#1653]\n",
      "Input [2]: [LAT#288, LON#289]\n",
      "\n",
      "(28) Union\n",
      "\n",
      "(29) RangeJoin\n",
      "Arguments: geometry#36: geometry, geom#1233: geometry, CONTAINS\n",
      "\n",
      "(30) Project\n",
      "Output [2]: [COMM#49, geometry#36]\n",
      "Input [3]: [COMM#49, geometry#36, geom#1233]\n",
      "\n",
      "(31) Exchange\n",
      "Input [2]: [COMM#49, geometry#36]\n",
      "Arguments: hashpartitioning(COMM#49, 1000), ENSURE_REQUIREMENTS, [plan_id=2728]\n",
      "\n",
      "(32) Sort\n",
      "Input [2]: [COMM#49, geometry#36]\n",
      "Arguments: [COMM#49 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(33) Scan csv \n",
      "Output [1]: [Community#1558]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string>\n",
      "\n",
      "(34) Filter\n",
      "Input [1]: [Community#1558]\n",
      "Condition : isnotnull(Community#1558)\n",
      "\n",
      "(35) Exchange\n",
      "Input [1]: [Community#1558]\n",
      "Arguments: hashpartitioning(Community#1558, 1000), ENSURE_REQUIREMENTS, [plan_id=2729]\n",
      "\n",
      "(36) Sort\n",
      "Input [1]: [Community#1558]\n",
      "Arguments: [Community#1558 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(37) SortMergeJoin\n",
      "Left keys [1]: [COMM#49]\n",
      "Right keys [1]: [Community#1558]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(38) Project\n",
      "Output [2]: [geometry#36, Community#1558]\n",
      "Input [3]: [COMM#49, geometry#36, Community#1558]\n",
      "\n",
      "(39) HashAggregate\n",
      "Input [2]: [geometry#36, Community#1558]\n",
      "Keys [1]: [Community#1558]\n",
      "Functions [1]: [partial_sum(cast(isnotnull(geometry#36) as int))]\n",
      "Aggregate Attributes [1]: [sum#1604L]\n",
      "Results [2]: [Community#1558, sum#1605L]\n",
      "\n",
      "(40) HashAggregate\n",
      "Input [2]: [Community#1558, sum#1605L]\n",
      "Keys [1]: [Community#1558]\n",
      "Functions [1]: [sum(cast(isnotnull(geometry#36) as int))]\n",
      "Aggregate Attributes [1]: [sum(cast(isnotnull(geometry#36) as int))#1549L]\n",
      "Results [2]: [Community#1558, sum(cast(isnotnull(geometry#36) as int))#1549L AS Sum_of_Crimes#1550L]\n",
      "\n",
      "(41) Sort\n",
      "Input [2]: [Community#1558, Sum_of_Crimes#1550L]\n",
      "Arguments: [Community#1558 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(42) SortMergeJoin\n",
      "Left keys [1]: [Community#365]\n",
      "Right keys [1]: [Community#1558]\n",
      "Join type: LeftOuter\n",
      "Join condition: None\n",
      "\n",
      "(43) Project\n",
      "Output [4]: [Community#365, Total Population#1148L, Sum_of_Crimes#1550L, (cast(Sum_of_Crimes#1550L as double) / cast(Total Population#1148L as double)) AS Ratio_of_Crimes_Per_Person#1576]\n",
      "Input [4]: [Community#365, Total Population#1148L, Community#1558, Sum_of_Crimes#1550L]\n",
      "\n",
      "(44) AdaptiveSparkPlan\n",
      "Output [4]: [Community#365, Total Population#1148L, Sum_of_Crimes#1550L, Ratio_of_Crimes_Per_Person#1576]\n",
      "Arguments: isFinalPlan=false"
     ]
    }
   ],
   "source": [
    "result_df.explain(mode=\"formatted\")\n",
    "df_final.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa5ac5-59b0-4108-851a-60602f306c01",
   "metadata": {},
   "source": [
    "## Shuffle_Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745e24cf-eb36-473a-954a-f43b7251e2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_1\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "|Community       |Total Population|Total Households|Estimated Median Income per Household|Income per Individual|\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "|Culver City     |77766           |34982           |$75,913.50                           |$34,148.68           |\n",
      "|Pico Rivera     |62942           |17109           |$55,758.00                           |$15,156.23           |\n",
      "|Malibu          |12645           |6864            |$123,681.00                          |$67,136.92           |\n",
      "|Hacienda Heights|53594           |16524           |$78,000.00                           |$24,048.81           |\n",
      "|Montebello      |62500           |19768           |$45,898.00                           |$14,516.99           |\n",
      "|Hawaiian Gardens|14254           |3703            |$37,543.00                           |$9,753.17            |\n",
      "|Westlake Village|16540           |6768            |$104,382.50                          |$42,712.26           |\n",
      "|Carson          |183428          |52452           |$74,351.50                           |$21,261.12           |\n",
      "|Glendale        |1150314         |457614          |$66,520.33                           |$26,462.89           |\n",
      "|Signal Hill     |11016           |4389            |$65,935.00                           |$26,269.85           |\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time taken: 10.19 seconds"
     ]
    }
   ],
   "source": [
    "print(\"Task_1\")\n",
    "start_time = time.time()\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Join με την βάση df3\n",
    "joined_df = flattened_df.hint(\"shuffle_hash\").join(df3, flattened_df[\"COMM\"] == df3[\"Community\"], \"inner\")\n",
    "\n",
    "# Καθαρισμός της στήλης \"Estimated Median Income\"\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"Cleaned Estimated Median Income\",\n",
    "    F.regexp_replace(F.col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(\"double\")\n",
    ")\n",
    "joined_df.select(\"Community\",\"Cleaned Estimated Median Income\",\"POP_2010\",\"HOUSING10\")\n",
    "# Ομαδοποίηση κατά την περιοχή \"Community\" και υπολογισμός των απαιτούμενων τιμών\n",
    "grouped_df = joined_df.groupBy(\"Community\").agg(\n",
    "    F.sum(\"POP_2010\").alias(\"Total Population\"),\n",
    "    F.sum(\"HOUSING10\").alias(\"Total Households\"),\n",
    "    F.avg(\"Cleaned Estimated Median Income\").alias(\"Avg Estimated Median Income\")\n",
    ")\n",
    "\n",
    "# Υπολογισμός της στήλης \"Income per Individual\"\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Income per Individual\",\n",
    "    (F.col(\"Total Households\") * F.col(\"Avg Estimated Median Income\")) / F.col(\"Total Population\")\n",
    ")\n",
    "\n",
    "# Δημιουργία της στήλης με το δολάριο για τα αποτελέσματα\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Estimated Median Income per Household\",\n",
    "    F.concat(F.lit(\"$\"), F.format_number(F.col(\"Avg Estimated Median Income\"), 2))\n",
    ")\n",
    "\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Income per Individual\",\n",
    "    F.concat(F.lit(\"$\"), F.format_number(F.col(\"Income per Individual\"), 2))\n",
    ")\n",
    "\n",
    "# Επιλογή των στηλών για εμφάνιση\n",
    "result_df = grouped_df.select(\n",
    "    \"Community\", \n",
    "    \"Total Population\", \n",
    "    \"Total Households\", \n",
    "    \"Estimated Median Income per Household\",\n",
    "    \"Income per Individual\"\n",
    ")\n",
    "\n",
    "# Εμφάνιση του αποτελέσματος\n",
    "result_df.show(truncate=False,n=10)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "719a4d9a-d226-415c-8a86-c9eeb5488ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_2\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "|Community       |Total Population|Sum_of_Crimes|Ratio_of_Crimes_Per_Person|\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "|Culver City     |77766           |2780         |0.03574827045238279       |\n",
      "|Pico Rivera     |62942           |2            |3.177528518318452E-5      |\n",
      "|Malibu          |12645           |1            |7.908264136022143E-5      |\n",
      "|Montebello      |62500           |6            |9.6E-5                    |\n",
      "|Westlake Village|16540           |2            |1.2091898428053205E-4     |\n",
      "|Hacienda Heights|53594           |NULL         |NULL                      |\n",
      "|Hawaiian Gardens|14254           |NULL         |NULL                      |\n",
      "|Carson          |183428          |862          |0.004699391586889679      |\n",
      "|Glendale        |1150314         |816          |7.093715281218867E-4      |\n",
      "|Signal Hill     |11016           |2            |1.8155410312273057E-4     |\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time taken: 86.56 seconds"
     ]
    }
   ],
   "source": [
    "print(\"Task_2\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Βήμα 1: Προσθήκη στήλης για γεωμετρικά σημεία στα δεδομένα εγκλημάτων\n",
    "df_combined = df_combined.withColumn(\"geom\", ST_Point(\"LON\", \"LAT\"))\n",
    "\n",
    "# Βήμα 2: Εντοπισμός αν τα σημεία ανήκουν σε κάποιο πολύγωνο\n",
    "df_joined = flattened_df.hint(\"shuffle_hash\").join(\n",
    "    df_combined,\n",
    "    ST_Contains(flattened_df[\"geometry\"], df_combined[\"geom\"]),\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_zip = df_joined.hint(\"shuffle_hash\").join(df3, df_joined[\"COMM\"] == df3[\"Community\"], \"inner\")\n",
    "\n",
    "df_zip.select(\"Community\",\"geometry\")\n",
    "# Βήμα 3: Προσθήκη στήλης \"Sum of Crimes\"\n",
    "df_aggregated = df_zip.groupBy(\"Community\").agg(\n",
    "    _sum(col(\"geometry\").isNotNull().cast(\"int\")).alias(\"Sum_of_Crimes\")\n",
    ")\n",
    "\n",
    "df_final=result_df.hint(\"shuffle_hash\").join(df_aggregated, result_df['Community'] == df_aggregated['Community'], \"left\")\n",
    "\n",
    "# Βήμα 4: Υπολογισμός της στήλης \"Ratio_of_Crimes_Per_Person\"\n",
    "df_final = df_final.withColumn(\n",
    "    \"Ratio_of_Crimes_Per_Person\", \n",
    "    col(\"Sum_of_Crimes\") / col(\"Total Population\")\n",
    ")\n",
    "\n",
    "# Βήμα 5: Εμφάνιση των αποτελεσμάτων\n",
    "df_final = df_final.select(result_df['Community'],\"Total Population\",\"Sum_of_Crimes\",\"Ratio_of_Crimes_Per_Person\")\n",
    "\n",
    "# Προβολή των αποτελεσμάτων\n",
    "df_final.show(truncate=False,n=10)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75c587de-e7fc-476c-86a2-7cf41e83ac01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (15)\n",
      "+- Project (14)\n",
      "   +- HashAggregate (13)\n",
      "      +- HashAggregate (12)\n",
      "         +- Project (11)\n",
      "            +- ShuffledHashJoin Inner BuildLeft (10)\n",
      "               :- Exchange (6)\n",
      "               :  +- Project (5)\n",
      "               :     +- Filter (4)\n",
      "               :        +- Generate (3)\n",
      "               :           +- Filter (2)\n",
      "               :              +- Scan geojson  (1)\n",
      "               +- Exchange (9)\n",
      "                  +- Filter (8)\n",
      "                     +- Scan csv  (7)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#25]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#25]\n",
      "Condition : ((size(features#25, true) > 0) AND isnotnull(features#25))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#25]\n",
      "Arguments: explode(features#25), false, [features#33]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : isnotnull(features#33.properties.COMM)\n",
      "\n",
      "(5) Project\n",
      "Output [3]: [features#33.properties.COMM AS COMM#49, features#33.properties.HOUSING10 AS HOUSING10#55L, features#33.properties.POP_2010 AS POP_2010#58L]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(6) Exchange\n",
      "Input [3]: [COMM#49, HOUSING10#55L, POP_2010#58L]\n",
      "Arguments: hashpartitioning(COMM#49, 1000), ENSURE_REQUIREMENTS, [plan_id=3801]\n",
      "\n",
      "(7) Scan csv \n",
      "Output [2]: [Community#365, Estimated Median Income#366]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string,Estimated Median Income:string>\n",
      "\n",
      "(8) Filter\n",
      "Input [2]: [Community#365, Estimated Median Income#366]\n",
      "Condition : isnotnull(Community#365)\n",
      "\n",
      "(9) Exchange\n",
      "Input [2]: [Community#365, Estimated Median Income#366]\n",
      "Arguments: hashpartitioning(Community#365, 1000), ENSURE_REQUIREMENTS, [plan_id=3802]\n",
      "\n",
      "(10) ShuffledHashJoin\n",
      "Left keys [1]: [COMM#49]\n",
      "Right keys [1]: [Community#365]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(11) Project\n",
      "Output [4]: [HOUSING10#55L, POP_2010#58L, Community#365, cast(regexp_replace(Estimated Median Income#366, [$,], , 1) as double) AS Cleaned Estimated Median Income#1720]\n",
      "Input [5]: [COMM#49, HOUSING10#55L, POP_2010#58L, Community#365, Estimated Median Income#366]\n",
      "\n",
      "(12) HashAggregate\n",
      "Input [4]: [HOUSING10#55L, POP_2010#58L, Community#365, Cleaned Estimated Median Income#1720]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [3]: [partial_sum(POP_2010#58L), partial_sum(HOUSING10#55L), partial_avg(Cleaned Estimated Median Income#1720)]\n",
      "Aggregate Attributes [4]: [sum#1835L, sum#1837L, sum#1839, count#1840L]\n",
      "Results [5]: [Community#365, sum#1836L, sum#1838L, sum#1841, count#1842L]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [5]: [Community#365, sum#1836L, sum#1838L, sum#1841, count#1842L]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [3]: [sum(POP_2010#58L), sum(HOUSING10#55L), avg(Cleaned Estimated Median Income#1720)]\n",
      "Aggregate Attributes [3]: [sum(POP_2010#58L)#1785L, sum(HOUSING10#55L)#1787L, avg(Cleaned Estimated Median Income#1720)#1789]\n",
      "Results [4]: [Community#365, sum(POP_2010#58L)#1785L AS Total Population#1786L, sum(HOUSING10#55L)#1787L AS Total Households#1788L, avg(Cleaned Estimated Median Income#1720)#1789 AS Avg Estimated Median Income#1790]\n",
      "\n",
      "(14) Project\n",
      "Output [5]: [Community#365, Total Population#1786L, Total Households#1788L, concat($, format_number(Avg Estimated Median Income#1790, 2)) AS Estimated Median Income per Household#1801, concat($, format_number(((cast(Total Households#1788L as double) * Avg Estimated Median Income#1790) / cast(Total Population#1786L as double)), 2)) AS Income per Individual#1808]\n",
      "Input [4]: [Community#365, Total Population#1786L, Total Households#1788L, Avg Estimated Median Income#1790]\n",
      "\n",
      "(15) AdaptiveSparkPlan\n",
      "Output [5]: [Community#365, Total Population#1786L, Total Households#1788L, Estimated Median Income per Household#1801, Income per Individual#1808]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (38)\n",
      "+- Project (37)\n",
      "   +- ShuffledHashJoin LeftOuter BuildLeft (36)\n",
      "      :- HashAggregate (13)\n",
      "      :  +- HashAggregate (12)\n",
      "      :     +- Project (11)\n",
      "      :        +- ShuffledHashJoin Inner BuildLeft (10)\n",
      "      :           :- Exchange (6)\n",
      "      :           :  +- Project (5)\n",
      "      :           :     +- Filter (4)\n",
      "      :           :        +- Generate (3)\n",
      "      :           :           +- Filter (2)\n",
      "      :           :              +- Scan geojson  (1)\n",
      "      :           +- Exchange (9)\n",
      "      :              +- Filter (8)\n",
      "      :                 +- Scan csv  (7)\n",
      "      +- HashAggregate (35)\n",
      "         +- HashAggregate (34)\n",
      "            +- Project (33)\n",
      "               +- ShuffledHashJoin Inner BuildLeft (32)\n",
      "                  :- Exchange (28)\n",
      "                  :  +- Project (27)\n",
      "                  :     +- RangeJoin (26)\n",
      "                  :        :- Project (18)\n",
      "                  :        :  +- Filter (17)\n",
      "                  :        :     +- Generate (16)\n",
      "                  :        :        +- Filter (15)\n",
      "                  :        :           +- Scan geojson  (14)\n",
      "                  :        +- Union (25)\n",
      "                  :           :- Project (21)\n",
      "                  :           :  +- Filter (20)\n",
      "                  :           :     +- Scan csv  (19)\n",
      "                  :           +- Project (24)\n",
      "                  :              +- Filter (23)\n",
      "                  :                 +- Scan csv  (22)\n",
      "                  +- Exchange (31)\n",
      "                     +- Filter (30)\n",
      "                        +- Scan csv  (29)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#25]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#25]\n",
      "Condition : ((size(features#25, true) > 0) AND isnotnull(features#25))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#25]\n",
      "Arguments: explode(features#25), false, [features#33]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : isnotnull(features#33.properties.COMM)\n",
      "\n",
      "(5) Project\n",
      "Output [2]: [features#33.properties.COMM AS COMM#49, features#33.properties.POP_2010 AS POP_2010#58L]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(6) Exchange\n",
      "Input [2]: [COMM#49, POP_2010#58L]\n",
      "Arguments: hashpartitioning(COMM#49, 1000), ENSURE_REQUIREMENTS, [plan_id=4005]\n",
      "\n",
      "(7) Scan csv \n",
      "Output [1]: [Community#365]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string>\n",
      "\n",
      "(8) Filter\n",
      "Input [1]: [Community#365]\n",
      "Condition : isnotnull(Community#365)\n",
      "\n",
      "(9) Exchange\n",
      "Input [1]: [Community#365]\n",
      "Arguments: hashpartitioning(Community#365, 1000), ENSURE_REQUIREMENTS, [plan_id=4006]\n",
      "\n",
      "(10) ShuffledHashJoin\n",
      "Left keys [1]: [COMM#49]\n",
      "Right keys [1]: [Community#365]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(11) Project\n",
      "Output [2]: [POP_2010#58L, Community#365]\n",
      "Input [3]: [COMM#49, POP_2010#58L, Community#365]\n",
      "\n",
      "(12) HashAggregate\n",
      "Input [2]: [POP_2010#58L, Community#365]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [1]: [partial_sum(POP_2010#58L)]\n",
      "Aggregate Attributes [1]: [sum#1835L]\n",
      "Results [2]: [Community#365, sum#1836L]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [2]: [Community#365, sum#1836L]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [1]: [sum(POP_2010#58L)]\n",
      "Aggregate Attributes [1]: [sum(POP_2010#58L)#1785L]\n",
      "Results [2]: [Community#365, sum(POP_2010#58L)#1785L AS Total Population#1786L]\n",
      "\n",
      "(14) Scan geojson \n",
      "Output [1]: [features#2192]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(15) Filter\n",
      "Input [1]: [features#2192]\n",
      "Condition : ((size(features#2192, true) > 0) AND isnotnull(features#2192))\n",
      "\n",
      "(16) Generate\n",
      "Input [1]: [features#2192]\n",
      "Arguments: explode(features#2192), false, [features#33]\n",
      "\n",
      "(17) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : (isnotnull(features#33.geometry) AND isnotnull(features#33.properties.COMM))\n",
      "\n",
      "(18) Project\n",
      "Output [2]: [features#33.properties.COMM AS COMM#49, features#33.geometry AS geometry#36]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(19) Scan csv \n",
      "Output [2]: [LAT#214, LON#215]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(20) Filter\n",
      "Input [2]: [LAT#214, LON#215]\n",
      "Condition : isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )\n",
      "\n",
      "(21) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#1871]\n",
      "Input [2]: [LAT#214, LON#215]\n",
      "\n",
      "(22) Scan csv \n",
      "Output [2]: [LAT#288, LON#289]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(23) Filter\n",
      "Input [2]: [LAT#288, LON#289]\n",
      "Condition : isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )\n",
      "\n",
      "(24) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#2287]\n",
      "Input [2]: [LAT#288, LON#289]\n",
      "\n",
      "(25) Union\n",
      "\n",
      "(26) RangeJoin\n",
      "Arguments: geometry#36: geometry, geom#1871: geometry, CONTAINS\n",
      "\n",
      "(27) Project\n",
      "Output [2]: [COMM#49, geometry#36]\n",
      "Input [3]: [COMM#49, geometry#36, geom#1871]\n",
      "\n",
      "(28) Exchange\n",
      "Input [2]: [COMM#49, geometry#36]\n",
      "Arguments: hashpartitioning(COMM#49, 1000), ENSURE_REQUIREMENTS, [plan_id=4012]\n",
      "\n",
      "(29) Scan csv \n",
      "Output [1]: [Community#2196]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string>\n",
      "\n",
      "(30) Filter\n",
      "Input [1]: [Community#2196]\n",
      "Condition : isnotnull(Community#2196)\n",
      "\n",
      "(31) Exchange\n",
      "Input [1]: [Community#2196]\n",
      "Arguments: hashpartitioning(Community#2196, 1000), ENSURE_REQUIREMENTS, [plan_id=4013]\n",
      "\n",
      "(32) ShuffledHashJoin\n",
      "Left keys [1]: [COMM#49]\n",
      "Right keys [1]: [Community#2196]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(33) Project\n",
      "Output [2]: [geometry#36, Community#2196]\n",
      "Input [3]: [COMM#49, geometry#36, Community#2196]\n",
      "\n",
      "(34) HashAggregate\n",
      "Input [2]: [geometry#36, Community#2196]\n",
      "Keys [1]: [Community#2196]\n",
      "Functions [1]: [partial_sum(cast(isnotnull(geometry#36) as int))]\n",
      "Aggregate Attributes [1]: [sum#2242L]\n",
      "Results [2]: [Community#2196, sum#2243L]\n",
      "\n",
      "(35) HashAggregate\n",
      "Input [2]: [Community#2196, sum#2243L]\n",
      "Keys [1]: [Community#2196]\n",
      "Functions [1]: [sum(cast(isnotnull(geometry#36) as int))]\n",
      "Aggregate Attributes [1]: [sum(cast(isnotnull(geometry#36) as int))#2187L]\n",
      "Results [2]: [Community#2196, sum(cast(isnotnull(geometry#36) as int))#2187L AS Sum_of_Crimes#2188L]\n",
      "\n",
      "(36) ShuffledHashJoin\n",
      "Left keys [1]: [Community#365]\n",
      "Right keys [1]: [Community#2196]\n",
      "Join type: LeftOuter\n",
      "Join condition: None\n",
      "\n",
      "(37) Project\n",
      "Output [4]: [Community#365, Total Population#1786L, Sum_of_Crimes#2188L, (cast(Sum_of_Crimes#2188L as double) / cast(Total Population#1786L as double)) AS Ratio_of_Crimes_Per_Person#2214]\n",
      "Input [4]: [Community#365, Total Population#1786L, Community#2196, Sum_of_Crimes#2188L]\n",
      "\n",
      "(38) AdaptiveSparkPlan\n",
      "Output [4]: [Community#365, Total Population#1786L, Sum_of_Crimes#2188L, Ratio_of_Crimes_Per_Person#2214]\n",
      "Arguments: isFinalPlan=false"
     ]
    }
   ],
   "source": [
    "result_df.explain(mode=\"formatted\")\n",
    "df_final.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e272fa-0c1d-4a6d-9a0f-e752fa1bea87",
   "metadata": {},
   "source": [
    "## Shuffle_Replicate_NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ff1f5e9-4b61-4f1e-8cda-29f3d1ba150d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_1\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "|Community       |Total Population|Total Households|Estimated Median Income per Household|Income per Individual|\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "|Culver City     |77766           |34982           |$75,913.50                           |$34,148.68           |\n",
      "|Pico Rivera     |62942           |17109           |$55,758.00                           |$15,156.23           |\n",
      "|Malibu          |12645           |6864            |$123,681.00                          |$67,136.92           |\n",
      "|Hacienda Heights|53594           |16524           |$78,000.00                           |$24,048.81           |\n",
      "|Montebello      |62500           |19768           |$45,898.00                           |$14,516.99           |\n",
      "|Hawaiian Gardens|14254           |3703            |$37,543.00                           |$9,753.17            |\n",
      "|Westlake Village|16540           |6768            |$104,382.50                          |$42,712.26           |\n",
      "|Carson          |183428          |52452           |$74,351.50                           |$21,261.12           |\n",
      "|Glendale        |1150314         |457614          |$66,520.33                           |$26,462.89           |\n",
      "|Signal Hill     |11016           |4389            |$65,935.00                           |$26,269.85           |\n",
      "+----------------+----------------+----------------+-------------------------------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time taken: 13.05 seconds"
     ]
    }
   ],
   "source": [
    "print(\"Task_1\")\n",
    "start_time = time.time()\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Join με την βάση df3\n",
    "joined_df = flattened_df.hint(\"shuffle_replicate_nl\").join(df3, flattened_df[\"COMM\"] == df3[\"Community\"], \"inner\")\n",
    "\n",
    "# Καθαρισμός της στήλης \"Estimated Median Income\"\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"Cleaned Estimated Median Income\",\n",
    "    F.regexp_replace(F.col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(\"double\")\n",
    ")\n",
    "joined_df.select(\"Community\",\"Cleaned Estimated Median Income\",\"POP_2010\",\"HOUSING10\")\n",
    "# Ομαδοποίηση κατά την περιοχή \"Community\" και υπολογισμός των απαιτούμενων τιμών\n",
    "grouped_df = joined_df.groupBy(\"Community\").agg(\n",
    "    F.sum(\"POP_2010\").alias(\"Total Population\"),\n",
    "    F.sum(\"HOUSING10\").alias(\"Total Households\"),\n",
    "    F.avg(\"Cleaned Estimated Median Income\").alias(\"Avg Estimated Median Income\")\n",
    ")\n",
    "\n",
    "# Υπολογισμός της στήλης \"Income per Individual\"\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Income per Individual\",\n",
    "    (F.col(\"Total Households\") * F.col(\"Avg Estimated Median Income\")) / F.col(\"Total Population\")\n",
    ")\n",
    "\n",
    "# Δημιουργία της στήλης με το δολάριο για τα αποτελέσματα\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Estimated Median Income per Household\",\n",
    "    F.concat(F.lit(\"$\"), F.format_number(F.col(\"Avg Estimated Median Income\"), 2))\n",
    ")\n",
    "\n",
    "grouped_df = grouped_df.withColumn(\n",
    "    \"Income per Individual\",\n",
    "    F.concat(F.lit(\"$\"), F.format_number(F.col(\"Income per Individual\"), 2))\n",
    ")\n",
    "\n",
    "# Επιλογή των στηλών για εμφάνιση\n",
    "result_df = grouped_df.select(\n",
    "    \"Community\", \n",
    "    \"Total Population\", \n",
    "    \"Total Households\", \n",
    "    \"Estimated Median Income per Household\",\n",
    "    \"Income per Individual\"\n",
    ")\n",
    "\n",
    "# Εμφάνιση του αποτελέσματος\n",
    "result_df.show(truncate=False,n=10)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f76510a3-d1b5-45f5-91f6-aa37935e457b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_2\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "|Community       |Total Population|Sum_of_Crimes|Ratio_of_Crimes_Per_Person|\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "|Culver City     |77766           |2780         |0.03574827045238279       |\n",
      "|Pico Rivera     |62942           |2            |3.177528518318452E-5      |\n",
      "|Malibu          |12645           |1            |7.908264136022143E-5      |\n",
      "|Hacienda Heights|53594           |NULL         |NULL                      |\n",
      "|Montebello      |62500           |6            |9.6E-5                    |\n",
      "|Hawaiian Gardens|14254           |NULL         |NULL                      |\n",
      "|Westlake Village|16540           |2            |1.2091898428053205E-4     |\n",
      "|Carson          |183428          |862          |0.004699391586889679      |\n",
      "|Glendale        |1150314         |816          |7.093715281218867E-4      |\n",
      "|Signal Hill     |11016           |2            |1.8155410312273057E-4     |\n",
      "+----------------+----------------+-------------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time taken: 158.13 seconds"
     ]
    }
   ],
   "source": [
    "print(\"Task_2\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Βήμα 1: Προσθήκη στήλης για γεωμετρικά σημεία στα δεδομένα εγκλημάτων\n",
    "df_combined = df_combined.withColumn(\"geom\", ST_Point(\"LON\", \"LAT\"))\n",
    "\n",
    "# Βήμα 2: Εντοπισμός αν τα σημεία ανήκουν σε κάποιο πολύγωνο\n",
    "df_joined = flattened_df.hint(\"shuffle_replicate_nl\").join(\n",
    "    df_combined,\n",
    "    ST_Contains(flattened_df[\"geometry\"], df_combined[\"geom\"]),\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_zip = df_joined.hint(\"shuffle_replicate_nl\").join(df3, df_joined[\"COMM\"] == df3[\"Community\"], \"inner\")\n",
    "df_zip.select(\"Community\",\"geometry\")\n",
    "# Βήμα 3: Προσθήκη στήλης \"Sum of Crimes\"\n",
    "df_aggregated = df_zip.groupBy(\"Community\").agg(\n",
    "    _sum(col(\"geometry\").isNotNull().cast(\"int\")).alias(\"Sum_of_Crimes\")\n",
    ")\n",
    "\n",
    "df_final=result_df.hint(\"shuffle_replicate_nl\").join(df_aggregated, result_df['Community'] == df_aggregated['Community'], \"left\")\n",
    "\n",
    "# Βήμα 4: Υπολογισμός της στήλης \"Ratio_of_Crimes_Per_Person\"\n",
    "df_final = df_final.withColumn(\n",
    "    \"Ratio_of_Crimes_Per_Person\", \n",
    "    col(\"Sum_of_Crimes\") / col(\"Total Population\")\n",
    ")\n",
    "\n",
    "# Βήμα 5: Εμφάνιση των αποτελεσμάτων\n",
    "df_final = df_final.select(result_df['Community'],\"Total Population\",\"Sum_of_Crimes\",\"Ratio_of_Crimes_Per_Person\")\n",
    "\n",
    "# Προβολή των αποτελεσμάτων\n",
    "df_final.show(truncate=False,n=10)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27f0dc9f-cf79-46dd-9d04-1cea9b9eb3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (14)\n",
      "+- Project (13)\n",
      "   +- HashAggregate (12)\n",
      "      +- Exchange (11)\n",
      "         +- HashAggregate (10)\n",
      "            +- Project (9)\n",
      "               +- CartesianProduct Inner (8)\n",
      "                  :- Project (5)\n",
      "                  :  +- Filter (4)\n",
      "                  :     +- Generate (3)\n",
      "                  :        +- Filter (2)\n",
      "                  :           +- Scan geojson  (1)\n",
      "                  +- Filter (7)\n",
      "                     +- Scan csv  (6)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#25]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#25]\n",
      "Condition : ((size(features#25, true) > 0) AND isnotnull(features#25))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#25]\n",
      "Arguments: explode(features#25), false, [features#33]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : isnotnull(features#33.properties.COMM)\n",
      "\n",
      "(5) Project\n",
      "Output [3]: [features#33.properties.COMM AS COMM#49, features#33.properties.HOUSING10 AS HOUSING10#55L, features#33.properties.POP_2010 AS POP_2010#58L]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(6) Scan csv \n",
      "Output [2]: [Community#365, Estimated Median Income#366]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string,Estimated Median Income:string>\n",
      "\n",
      "(7) Filter\n",
      "Input [2]: [Community#365, Estimated Median Income#366]\n",
      "Condition : isnotnull(Community#365)\n",
      "\n",
      "(8) CartesianProduct\n",
      "Join type: Inner\n",
      "Join condition: (COMM#49 = Community#365)\n",
      "\n",
      "(9) Project\n",
      "Output [4]: [HOUSING10#55L, POP_2010#58L, Community#365, cast(regexp_replace(Estimated Median Income#366, [$,], , 1) as double) AS Cleaned Estimated Median Income#2354]\n",
      "Input [5]: [COMM#49, HOUSING10#55L, POP_2010#58L, Community#365, Estimated Median Income#366]\n",
      "\n",
      "(10) HashAggregate\n",
      "Input [4]: [HOUSING10#55L, POP_2010#58L, Community#365, Cleaned Estimated Median Income#2354]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [3]: [partial_sum(POP_2010#58L), partial_sum(HOUSING10#55L), partial_avg(Cleaned Estimated Median Income#2354)]\n",
      "Aggregate Attributes [4]: [sum#2469L, sum#2471L, sum#2473, count#2474L]\n",
      "Results [5]: [Community#365, sum#2470L, sum#2472L, sum#2475, count#2476L]\n",
      "\n",
      "(11) Exchange\n",
      "Input [5]: [Community#365, sum#2470L, sum#2472L, sum#2475, count#2476L]\n",
      "Arguments: hashpartitioning(Community#365, 1000), ENSURE_REQUIREMENTS, [plan_id=4790]\n",
      "\n",
      "(12) HashAggregate\n",
      "Input [5]: [Community#365, sum#2470L, sum#2472L, sum#2475, count#2476L]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [3]: [sum(POP_2010#58L), sum(HOUSING10#55L), avg(Cleaned Estimated Median Income#2354)]\n",
      "Aggregate Attributes [3]: [sum(POP_2010#58L)#2419L, sum(HOUSING10#55L)#2421L, avg(Cleaned Estimated Median Income#2354)#2423]\n",
      "Results [4]: [Community#365, sum(POP_2010#58L)#2419L AS Total Population#2420L, sum(HOUSING10#55L)#2421L AS Total Households#2422L, avg(Cleaned Estimated Median Income#2354)#2423 AS Avg Estimated Median Income#2424]\n",
      "\n",
      "(13) Project\n",
      "Output [5]: [Community#365, Total Population#2420L, Total Households#2422L, concat($, format_number(Avg Estimated Median Income#2424, 2)) AS Estimated Median Income per Household#2435, concat($, format_number(((cast(Total Households#2422L as double) * Avg Estimated Median Income#2424) / cast(Total Population#2420L as double)), 2)) AS Income per Individual#2442]\n",
      "Input [4]: [Community#365, Total Population#2420L, Total Households#2422L, Avg Estimated Median Income#2424]\n",
      "\n",
      "(14) AdaptiveSparkPlan\n",
      "Output [5]: [Community#365, Total Population#2420L, Total Households#2422L, Estimated Median Income per Household#2435, Income per Individual#2442]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (38)\n",
      "+- Project (37)\n",
      "   +- SortMergeJoin LeftOuter (36)\n",
      "      :- Sort (13)\n",
      "      :  +- HashAggregate (12)\n",
      "      :     +- Exchange (11)\n",
      "      :        +- HashAggregate (10)\n",
      "      :           +- Project (9)\n",
      "      :              +- CartesianProduct Inner (8)\n",
      "      :                 :- Project (5)\n",
      "      :                 :  +- Filter (4)\n",
      "      :                 :     +- Generate (3)\n",
      "      :                 :        +- Filter (2)\n",
      "      :                 :           +- Scan geojson  (1)\n",
      "      :                 +- Filter (7)\n",
      "      :                    +- Scan csv  (6)\n",
      "      +- Sort (35)\n",
      "         +- HashAggregate (34)\n",
      "            +- Exchange (33)\n",
      "               +- HashAggregate (32)\n",
      "                  +- Project (31)\n",
      "                     +- CartesianProduct Inner (30)\n",
      "                        :- Project (27)\n",
      "                        :  +- RangeJoin (26)\n",
      "                        :     :- Project (18)\n",
      "                        :     :  +- Filter (17)\n",
      "                        :     :     +- Generate (16)\n",
      "                        :     :        +- Filter (15)\n",
      "                        :     :           +- Scan geojson  (14)\n",
      "                        :     +- Union (25)\n",
      "                        :        :- Project (21)\n",
      "                        :        :  +- Filter (20)\n",
      "                        :        :     +- Scan csv  (19)\n",
      "                        :        +- Project (24)\n",
      "                        :           +- Filter (23)\n",
      "                        :              +- Scan csv  (22)\n",
      "                        +- Filter (29)\n",
      "                           +- Scan csv  (28)\n",
      "\n",
      "\n",
      "(1) Scan geojson \n",
      "Output [1]: [features#25]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [features#25]\n",
      "Condition : ((size(features#25, true) > 0) AND isnotnull(features#25))\n",
      "\n",
      "(3) Generate\n",
      "Input [1]: [features#25]\n",
      "Arguments: explode(features#25), false, [features#33]\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : isnotnull(features#33.properties.COMM)\n",
      "\n",
      "(5) Project\n",
      "Output [2]: [features#33.properties.COMM AS COMM#49, features#33.properties.POP_2010 AS POP_2010#58L]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(6) Scan csv \n",
      "Output [1]: [Community#365]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string>\n",
      "\n",
      "(7) Filter\n",
      "Input [1]: [Community#365]\n",
      "Condition : isnotnull(Community#365)\n",
      "\n",
      "(8) CartesianProduct\n",
      "Join type: Inner\n",
      "Join condition: (COMM#49 = Community#365)\n",
      "\n",
      "(9) Project\n",
      "Output [2]: [POP_2010#58L, Community#365]\n",
      "Input [3]: [COMM#49, POP_2010#58L, Community#365]\n",
      "\n",
      "(10) HashAggregate\n",
      "Input [2]: [POP_2010#58L, Community#365]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [1]: [partial_sum(POP_2010#58L)]\n",
      "Aggregate Attributes [1]: [sum#2469L]\n",
      "Results [2]: [Community#365, sum#2470L]\n",
      "\n",
      "(11) Exchange\n",
      "Input [2]: [Community#365, sum#2470L]\n",
      "Arguments: hashpartitioning(Community#365, 1000), ENSURE_REQUIREMENTS, [plan_id=4987]\n",
      "\n",
      "(12) HashAggregate\n",
      "Input [2]: [Community#365, sum#2470L]\n",
      "Keys [1]: [Community#365]\n",
      "Functions [1]: [sum(POP_2010#58L)]\n",
      "Aggregate Attributes [1]: [sum(POP_2010#58L)#2419L]\n",
      "Results [2]: [Community#365, sum(POP_2010#58L)#2419L AS Total Population#2420L]\n",
      "\n",
      "(13) Sort\n",
      "Input [2]: [Community#365, Total Population#2420L]\n",
      "Arguments: [Community#365 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(14) Scan geojson \n",
      "Output [1]: [features#2830]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(15) Filter\n",
      "Input [1]: [features#2830]\n",
      "Condition : ((size(features#2830, true) > 0) AND isnotnull(features#2830))\n",
      "\n",
      "(16) Generate\n",
      "Input [1]: [features#2830]\n",
      "Arguments: explode(features#2830), false, [features#33]\n",
      "\n",
      "(17) Filter\n",
      "Input [1]: [features#33]\n",
      "Condition : (isnotnull(features#33.geometry) AND isnotnull(features#33.properties.COMM))\n",
      "\n",
      "(18) Project\n",
      "Output [2]: [features#33.properties.COMM AS COMM#49, features#33.geometry AS geometry#36]\n",
      "Input [1]: [features#33]\n",
      "\n",
      "(19) Scan csv \n",
      "Output [2]: [LAT#214, LON#215]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(20) Filter\n",
      "Input [2]: [LAT#214, LON#215]\n",
      "Condition : isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )\n",
      "\n",
      "(21) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#2509]\n",
      "Input [2]: [LAT#214, LON#215]\n",
      "\n",
      "(22) Scan csv \n",
      "Output [2]: [LAT#288, LON#289]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(23) Filter\n",
      "Input [2]: [LAT#288, LON#289]\n",
      "Condition : isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )\n",
      "\n",
      "(24) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#2931]\n",
      "Input [2]: [LAT#288, LON#289]\n",
      "\n",
      "(25) Union\n",
      "\n",
      "(26) RangeJoin\n",
      "Arguments: geometry#36: geometry, geom#2509: geometry, CONTAINS\n",
      "\n",
      "(27) Project\n",
      "Output [2]: [COMM#49, geometry#36]\n",
      "Input [3]: [COMM#49, geometry#36, geom#2509]\n",
      "\n",
      "(28) Scan csv \n",
      "Output [1]: [Community#2834]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Community)]\n",
      "ReadSchema: struct<Community:string>\n",
      "\n",
      "(29) Filter\n",
      "Input [1]: [Community#2834]\n",
      "Condition : isnotnull(Community#2834)\n",
      "\n",
      "(30) CartesianProduct\n",
      "Join type: Inner\n",
      "Join condition: (COMM#49 = Community#2834)\n",
      "\n",
      "(31) Project\n",
      "Output [2]: [geometry#36, Community#2834]\n",
      "Input [3]: [COMM#49, geometry#36, Community#2834]\n",
      "\n",
      "(32) HashAggregate\n",
      "Input [2]: [geometry#36, Community#2834]\n",
      "Keys [1]: [Community#2834]\n",
      "Functions [1]: [partial_sum(cast(isnotnull(geometry#36) as int))]\n",
      "Aggregate Attributes [1]: [sum#2880L]\n",
      "Results [2]: [Community#2834, sum#2881L]\n",
      "\n",
      "(33) Exchange\n",
      "Input [2]: [Community#2834, sum#2881L]\n",
      "Arguments: hashpartitioning(Community#2834, 1000), ENSURE_REQUIREMENTS, [plan_id=4989]\n",
      "\n",
      "(34) HashAggregate\n",
      "Input [2]: [Community#2834, sum#2881L]\n",
      "Keys [1]: [Community#2834]\n",
      "Functions [1]: [sum(cast(isnotnull(geometry#36) as int))]\n",
      "Aggregate Attributes [1]: [sum(cast(isnotnull(geometry#36) as int))#2825L]\n",
      "Results [2]: [Community#2834, sum(cast(isnotnull(geometry#36) as int))#2825L AS Sum_of_Crimes#2826L]\n",
      "\n",
      "(35) Sort\n",
      "Input [2]: [Community#2834, Sum_of_Crimes#2826L]\n",
      "Arguments: [Community#2834 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(36) SortMergeJoin\n",
      "Left keys [1]: [Community#365]\n",
      "Right keys [1]: [Community#2834]\n",
      "Join type: LeftOuter\n",
      "Join condition: None\n",
      "\n",
      "(37) Project\n",
      "Output [4]: [Community#365, Total Population#2420L, Sum_of_Crimes#2826L, (cast(Sum_of_Crimes#2826L as double) / cast(Total Population#2420L as double)) AS Ratio_of_Crimes_Per_Person#2852]\n",
      "Input [4]: [Community#365, Total Population#2420L, Community#2834, Sum_of_Crimes#2826L]\n",
      "\n",
      "(38) AdaptiveSparkPlan\n",
      "Output [4]: [Community#365, Total Population#2420L, Sum_of_Crimes#2826L, Ratio_of_Crimes_Per_Person#2852]\n",
      "Arguments: isFinalPlan=false"
     ]
    }
   ],
   "source": [
    "result_df.explain(mode=\"formatted\")\n",
    "df_final.explain(mode=\"formatted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
