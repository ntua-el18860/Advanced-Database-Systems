{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bbee2d5-f36d-4863-a000-b01834bcbfc6",
   "metadata": {},
   "source": [
    "# DataFrame - Query5 - 2 executors × 4 cores/8GB memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11330a79-6668-45e5-bf06-a8052c50965c",
   "metadata": {},
   "source": [
    "## Import Data from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8082bc-3ce1-4a15-854f-65cb15819487",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>3487</td><td>application_1732639283265_3443</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3443/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-233.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3443_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql.functions import col, lower, when\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GeoJSON read\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create sedona context\n",
    "sedona = SedonaContext.create(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40eb1bb-bcc4-4cc5-9505-f2b112df50ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DR_NO: integer (nullable = true)\n",
      " |-- Date Rptd: string (nullable = true)\n",
      " |-- DATE OCC: string (nullable = true)\n",
      " |-- TIME OCC: integer (nullable = true)\n",
      " |-- AREA : integer (nullable = true)\n",
      " |-- AREA NAME: string (nullable = true)\n",
      " |-- Rpt Dist No: integer (nullable = true)\n",
      " |-- Part 1-2: integer (nullable = true)\n",
      " |-- Crm Cd: integer (nullable = true)\n",
      " |-- Crm Cd Desc: string (nullable = true)\n",
      " |-- Mocodes: string (nullable = true)\n",
      " |-- Vict Age: integer (nullable = true)\n",
      " |-- Vict Sex: string (nullable = true)\n",
      " |-- Vict Descent: string (nullable = true)\n",
      " |-- Premis Cd: integer (nullable = true)\n",
      " |-- Premis Desc: string (nullable = true)\n",
      " |-- Weapon Used Cd: integer (nullable = true)\n",
      " |-- Weapon Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Status Desc: string (nullable = true)\n",
      " |-- Crm Cd 1: integer (nullable = true)\n",
      " |-- Crm Cd 2: integer (nullable = true)\n",
      " |-- Crm Cd 3: integer (nullable = true)\n",
      " |-- Crm Cd 4: integer (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- Cross Street: string (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- LON: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "#load data from crimes\n",
    "data_path = 's3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv'\n",
    "\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "data2_path = 's3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv'\n",
    "df2 = spark.read.csv(data2_path,header = True, inferSchema = True)\n",
    "\n",
    "df_combined = df.union(df2)\n",
    "df_combined.columns\n",
    "df_combined.count()\n",
    "df_combined.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc9c029-63da-481a-97d7-4ddda44c054f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- X: double (nullable = true)\n",
      " |-- Y: double (nullable = true)\n",
      " |-- FID: integer (nullable = true)\n",
      " |-- DIVISION: string (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- PREC: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "#load data from LA income\n",
    "data3_path = 's3://initial-notebook-data-bucket-dblab-905418150721/LA_Police_Stations.csv'\n",
    "df3 = spark.read.csv(data3_path,header = True, inferSchema = True)\n",
    "df3.columns\n",
    "df3.count()\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b244ad44-b15a-428e-8c25-1239fda98ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+------+\n",
      "|division        |average_distance  |#     |\n",
      "+----------------+------------------+------+\n",
      "|77th street     |14667.404665088128|206981|\n",
      "|southwest       |11919.183392928315|192367|\n",
      "|pacific         |23217.837897333302|171166|\n",
      "|central         |19800.237298414453|166946|\n",
      "|north hollywood |16209.757573536073|164710|\n",
      "|southeast       |18117.102515811494|161256|\n",
      "|hollywood       |34031.54247813007 |151053|\n",
      "|newton          |12954.564101781074|148886|\n",
      "|olympic         |16840.905966885035|145135|\n",
      "|mission         |20202.014726011737|143777|\n",
      "|northeast       |12730.983942391795|142833|\n",
      "|van nuys        |14156.99316736504 |142327|\n",
      "|topanga         |9801.350722735635 |138708|\n",
      "|devonshire      |18727.924888877016|138044|\n",
      "|wilshire        |18742.94184561195 |136374|\n",
      "|rampart         |16044.949875248454|136104|\n",
      "|west los angeles|13881.883428494097|134369|\n",
      "|harbor          |15430.634370288273|133031|\n",
      "|west valley     |11522.972959349752|131585|\n",
      "|hollenbeck      |18947.554681490175|114665|\n",
      "|foothill        |15852.825436448838|113020|\n",
      "+----------------+------------------+------+\n",
      "\n",
      "Time taken: 25.28 seconds"
     ]
    }
   ],
   "source": [
    "df3 = df3.withColumn(\"geom_police\", ST_Point(\"X\", \"Y\"))\n",
    "df_combined = df_combined.withColumn(\"geom_crimes\", ST_Point(\"LON\", \"LAT\"))\n",
    "\n",
    "normalized_df3 = df3.withColumn(\"area_name\", lower(col(\"DIVISION\")))\n",
    "normalized_df_combined = df_combined.withColumn(\"division\", lower(col(\"AREA NAME\")))\n",
    "\n",
    "normalized_df3=normalized_df3.select(\"area_name\",\"geom_police\")\n",
    "normalized_df_combined=normalized_df_combined.select(\"division\",\"geom_crimes\")\n",
    "\n",
    "normalized_df_combined = normalized_df_combined.withColumn(\n",
    "    \"division\",\n",
    "    when(col(\"division\") == \"n hollywood\", \"north hollywood\")\n",
    "    .when(col(\"division\") == \"west la\", \"west los angeles\")\n",
    "    .otherwise(col(\"division\"))\n",
    ")\n",
    "# Ενσωμάτωση της θέσης του αστυνομικού τμήματος στο normalized_df_combined\n",
    "normalized_df_combined = normalized_df_combined.join(\n",
    "    normalized_df3,\n",
    "    normalized_df_combined[\"division\"] == normalized_df3[\"area_name\"],\n",
    "    \"left\"\n",
    ").drop(\"area_name\")\n",
    "\n",
    "normalized_df_combined=normalized_df_combined.withColumn(\"distance\",ST_DistanceSphere(\"geom_police\", \"geom_crimes\"))\n",
    "\n",
    "normalized_df_combined = normalized_df_combined.groupBy(\"division\").agg(\n",
    "    F.avg(\"distance\").alias(\"average_distance\"),\n",
    "    F.count(\"geom_crimes\").alias(\"#\")\n",
    ")\n",
    "\n",
    "normalized_df_combined=normalized_df_combined.select(\"division\",\"average_distance\",\"#\")\n",
    "normalized_df_combined = normalized_df_combined.orderBy(col(\"#\").desc())\n",
    "\n",
    "normalized_df_combined.show(truncate=False,n=25)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
